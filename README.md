## Data App - Prevendo Valores de Im√≥veis
> ##### Um App utilizado para exibir a solu√ß√£o de Machine Learning para o problema de predi√ß√£o de valores de im√≥veis da cidade de Boston
##### Separamos ``` 80% ``` de base de dados para treino e ```20%``` para teste
#### Obs: a separa√ß√£o de dados de treino e de teste vai variar de cada desenvolvedor. veja üëâ [Minerando Dados](https://minerandodados.com.br/split-dataset-como-separar/) um exemplo 
![data-app-screen](https://user-images.githubusercontent.com/19332627/82452717-05185f80-9a86-11ea-9971-90761a4fb528.PNG)
####  Semana de Data Science do [Minerando Dados](https://minerandodados.com.br/)
### Processo de Data Science 
### Etapas:

1. Coleta de Dados
2. Limpeza e Formata√ß√£o
3. An√°lise e Explora√ß√£o 
4. Cria√ß√£o de Modelo
5. Interpreta√ß√£o de Resultado de Modelo

Vou pular algumas etapas e ir logo para a etapa ```4 ``` que tem foco na escolha de algoritmo vencedor.
Nessa etapa, aplicamos os algorimtos que se adequam com o nosso problema. Lembrando que nesse caso, nosso problema √© prever valor de um im√≥vel baseado nos valores dos dados que j√° temos. Esse √© um problema para *algoritmo de aprendizado supervisionado*

#### Defini√ß√£o da Baseline
> √â importante definir uma base line para termos marco no nosso projeto 
###### Nossa Baseline foi definida da seguinte forma:
``` def retorna_baseline(num_quartos):
  if num_quartos <= 4:
    return dic_baseline.get('Pequeno')
  elif num_quartos < 7:
    return dic_baseline.get('Medio')
  else:
    return dic_baseline.get('Grande') 
```

> desta forma, clasificamos assim os imoveis em tr√™s categorias definido no c√≥digo em cima

###### Apos o treinamento, obtemos :
![predict_baseline](https://user-images.githubusercontent.com/19332627/82248838-2f034200-991f-11ea-9ac1-69cf2b4a77a9.PNG)
> Performance do modelo avaliado com os dados de teste

> erro quadr√°tico: **6.205816494411828**

Obs: esse modelo erra ```+6 ou -6 ```

#### Regress√£o Linear
![rl](https://user-images.githubusercontent.com/19332627/82250696-50196200-9922-11ea-8137-68749949d93e.PNG)
> Performance do modelo avaliado com os dados de teste.

> erro quadr√°tico de: **4.460277295153906**

#### Decision Tree 
![decision tree](https://user-images.githubusercontent.com/19332627/82252671-cff4fb80-9925-11ea-9b61-dcc083f38b7f.PNG)
> Performance do modelo avaliado com os dados de teste

> erro quadr√°tico de: **4.643988873055277**

Por √∫ltimo, mas nao menos importanbte, testamos o nosso 
#### Random Forest
![random_forest](https://user-images.githubusercontent.com/19332627/82253900-409d1780-9928-11ea-89ce-4133f7ab5945.PNG)
> Performance do modelo avaliado com os dados de teste.

> erro quadr√°tico de: **3.3218209875713334**

Note-se claramente que o Random Forest se saiu melhor que os demais algoritmos testados para o nosso problema
Desta forma, √© com ele que terminamos a etapa ``` 4 ``` e decidimos a etapa ``` 5 ```.


> Psiu!!! essa escolha n√£o quer dizer que o Random Forest √© melhor que todos ou se sair√° melhor que os restantes algoritmos. Mas, para esse problema ele se sa√≠ melhor que os os demais testados. Ali√°s,  poder√≠amos usar o ``` GridSearchCV ``` com seus famosos hiperpar√¢metros o que provavelmente seria um bra√ßo de ferro bem interessante.
